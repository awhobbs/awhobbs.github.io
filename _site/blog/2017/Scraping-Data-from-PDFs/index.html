<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Andrew Hobbs | Scraping Data from Many Big PDFs</title>
  <meta name="description" content="hobbservations">

  <link rel="shortcut icon" href="http://localhost:4000//assets/img/favicon.ico">

  <link rel="stylesheet" href="http://localhost:4000//assets/css/main.css">
  <link rel="canonical" href="http://localhost:4000//blog/2017/Scraping-Data-from-PDFs/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Andrew</strong> Hobbs
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="http://localhost:4000//">about</a>

        <!-- Blog -->
        <a class="page-link" href="http://localhost:4000//blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="http://localhost:4000//projects/">projects</a>
          
        
          
            <a class="page-link" href="http://localhost:4000//teaching/">teaching</a>
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="http://localhost:4000//assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Scraping Data from Many Big PDFs</h1>
    <p class="post-meta">September 29, 2017</p>
  </header>

  <article class="post-content">
    <p>The <a href="http://calcarbondash.org/">California Carbon Dashboard</a>’s data comes from PDFs downloaded from Intercontinental Exchange (ICE). Unfortunately, these PDFs are daily and are more than 2000 pages long. In order to get the data out of them in a reasonable amount of time, we needed to figure out a way of quickly identifying the right pages and pulling tables from them. I figured I’d document this here, as I think it might be useful to someone else’s research.</p>

<p>The basic steps are:</p>
<ol>
  <li>Start with a good guess for where the useful data is. I found it in the first PDF, and then the script saves updates a record of where it found the first page each day. The page changes over time, but rarely moves far in a single day, so this saves a lot of time searching.</li>
  <li>If the script doesn’t find a relevant page where yesterday’s began, it jumps forward 3 pages, back 6, then forward 9, etc. Since the data we are looking for is always about 5 pages long, we will never fail to find it this way. Further, by jumping a bit further, we again save a lot of time.</li>
  <li>Since all the pages we want are always sequential, and are also the only pages with ‘California’ in the title, we start moving forward from the first useful page we find. Once we reach the last useful page, we move backward from the first useful one we found. This ensures we get the whole series in the minimum amount of time.</li>
  <li>We then record the page where the data started to start tomorrow’s search.</li>
</ol>

<p>This simple-yet-pretty-hacky algorithm dramatically reduced the time it takes to extract the data. The <code class="highlighter-rouge">tabula-py</code> pulls tables from PDFS beautifully, but due to general messiness of PDFS we had to write a few more lines of code to clean it up. In the end, we replaced our old 800+ line scraper script with one that is only a few dozen lines and dramatically faster. The code is below - I hope that this can saves others some time when trying to pull tables from PDFs, especially large ones.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tabula</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="s">'./log/parser.log'</span><span class="p">,</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">page</span><span class="p">):</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Starting "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span> <span class="o">+</span>  <span class="s">" on page "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">))</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">start_page</span> <span class="o">=</span> <span class="n">page</span>
    <span class="n">price_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">found_data</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">last_page_was_useful</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">timeout</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">jump</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">jump_sign</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c"># a ridiculously large number</span>
    <span class="n">last_page</span> <span class="o">=</span> <span class="mf">10e1000</span>
    <span class="n">direction</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">useless_pages</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">harvested_pages</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">useful</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="nb">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s">'California'</span><span class="p">))</span>
        <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Page "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">)</span> <span class="o">+</span> <span class="s">" seems to be blank."</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">timeout</span> <span class="ow">and</span> <span class="p">(</span><span class="n">last_page_was_useful</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">found_data</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">tabula</span><span class="o">.</span><span class="n">read_pdf</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">pages</span> <span class="o">=</span> <span class="n">page</span><span class="p">,</span> <span class="n">silent</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
        <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"ERROR! "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">)</span> <span class="o">+</span> <span class="s">" returned an empty dataframe"</span><span class="p">)</span>

        <span class="c"># Check if the page contains the word "California" in the first column</span>
        <span class="c"># (which is how it interprets the big gray bar)</span>
        <span class="k">if</span> <span class="n">useful</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
            <span class="n">last_page_was_useful</span> <span class="o">=</span> <span class="bp">True</span>

            <span class="c"># This stuff happens on the first useful page we find</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">found_data</span><span class="p">:</span>
                <span class="c"># record that we found the data!</span>
                <span class="n">found_data</span> <span class="o">=</span> <span class="bp">True</span>
                <span class="c"># check if this is the earliest useful page</span>
                <span class="c"># if it was, go backward</span>
                <span class="k">if</span> <span class="n">page</span> <span class="o">&lt;</span> <span class="n">last_page</span><span class="p">:</span>
                    <span class="n">direction</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="c"># add this page to the list of pages we've harvested</span>
            <span class="n">harvested_pages</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
            <span class="c"># on every useful page, add the data to the set</span>
            <span class="n">price_data</span> <span class="o">=</span> <span class="n">price_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="c"># record the page in the data because why not</span>
            <span class="n">price_data</span><span class="p">[</span><span class="s">'page'</span><span class="p">]</span> <span class="o">=</span> <span class="n">page</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Extracted useful data from page "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">))</span>
            <span class="c"># increment or decrement depending on how we found the page</span>
            <span class="n">page</span> <span class="o">+=</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">direction</span>
        <span class="c"># This happens if the page was not useful</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">useless_pages</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
            <span class="c">#This stuff happens if we haven't found the data yet</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">found_data</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">jump</span> <span class="o">&lt;</span> <span class="mi">1000</span><span class="p">:</span>
                    <span class="n">page</span> <span class="o">=</span> <span class="n">page</span> <span class="o">+</span> <span class="n">jump</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Nothing to see here, jumping to page"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">))</span>
                    <span class="n">jump_size</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">jump</span><span class="p">)</span> <span class="o">+</span> <span class="mi">3</span>
                    <span class="n">jump_sign</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
                    <span class="n">jump</span> <span class="o">=</span> <span class="n">jump_sign</span> <span class="o">*</span> <span class="n">jump_size</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s">"Can't find data! Try a new start page?"</span><span class="p">)</span>
                    <span class="n">timeout</span> <span class="o">=</span> <span class="bp">True</span>
	        <span class="c"># If we've found the data, but this page is not useful</span>
            <span class="c"># we need to go back to wherever we started in the data</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c"># Check that pages right before and after</span>
                <span class="c"># harvested pages are useless_pages</span>
                <span class="k">if</span> <span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">harvested_pages</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">in</span> <span class="n">useless_pages</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">harvested_pages</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">in</span> <span class="n">useless_pages</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"No useful data on page "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">)</span> <span class="o">+</span>
                                     <span class="s">", that's it!"</span><span class="p">)</span>
                        <span class="n">last_page_was_useful</span> <span class="o">=</span> <span class="bp">False</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Checking the end..."</span><span class="p">)</span>
                        <span class="n">page</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">harvested_pages</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                        <span class="n">direction</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Checking the beginning..."</span><span class="p">)</span>
                    <span class="n">page</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">harvested_pages</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="n">direction</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">last_page</span> <span class="o">=</span> <span class="n">page</span>

    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Done parsing "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">file</span><span class="p">))</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">start_page</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">harvested_pages</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">Exception</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"No pages harvested"</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s">'data'</span><span class="p">:</span> <span class="n">price_data</span><span class="p">,</span> <span class="s">'start_page'</span><span class="p">:</span> <span class="n">start_page</span><span class="p">,</span> <span class="s">'filename'</span><span class="p">:</span> <span class="nb">file</span><span class="p">}</span>

<span class="n">target_folder</span> <span class="o">=</span> <span class="s">'./pdf'</span>
<span class="n">archive_folder</span> <span class="o">=</span> <span class="s">'./archive'</span>

<span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">target_folder</span><span class="p">)</span> \
                    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_folder</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span> \
                    <span class="ow">and</span> <span class="ow">not</span> <span class="n">f</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'.'</span><span class="p">)]</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'./log/start_page.pickle'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">start_page</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">start_page</span> <span class="o">=</span> <span class="mi">2159</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">files</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">target_folder</span> <span class="o">+</span> <span class="s">"/"</span> <span class="o">+</span> <span class="nb">file</span><span class="p">,</span> <span class="n">start_page</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s">'data'</span><span class="p">]</span>
    <span class="c"># start the next day on the starting page from today!</span>
    <span class="n">start_page</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s">'start_page'</span><span class="p">]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'./log/start_page.pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">start_page</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="c"># save the thing in a pickle in case something happens</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'./data/datapickle.pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="c"># Move the file to the archive</span>
    <span class="n">os</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">target_folder</span> <span class="o">+</span> <span class="s">"/"</span> <span class="o">+</span> <span class="nb">file</span><span class="p">,</span> <span class="n">archive_folder</span> <span class="o">+</span> <span class="s">"/"</span> <span class="o">+</span> <span class="nb">file</span><span class="p">)</span>
</code></pre></div></div>

  </article>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2019 Andrew Hobbs.
    
    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="http://localhost:4000//assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="http://localhost:4000//assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="http://localhost:4000//assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="http://localhost:4000//assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-107899414-1', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
